{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from prettytable import PrettyTable\n",
    "import tempfile\n",
    "import os\n",
    "import shutil\n",
    "from mlflow.utils.autologging_utils import try_mlflow_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.set_tracking_uri(\"http://localhost:5000/\")\n",
    "mlflow.start_run(run_name=\"CaptumExample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "import torchtext.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        #text = text.permute(1, 0)\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "\n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prettytable in /home/ubuntu/anaconda3/lib/python3.8/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from prettytable) (49.6.0.post20200814)\r\n",
      "Requirement already satisfied: wcwidth in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from prettytable) (0.2.5)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_model_parameters(model):\n",
    "        table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "        total_params = 0\n",
    "\n",
    "        for name, parameter in model.named_parameters():\n",
    "\n",
    "            if not parameter.requires_grad:\n",
    "                continue\n",
    "\n",
    "            param = parameter.nonzero(as_tuple=False).size(0)\n",
    "            table.add_row([name, param])\n",
    "            total_params += param\n",
    "        print(table)\n",
    "        print(f\"Total Trainable Params: {total_params}\")\n",
    "        return table, total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+\n",
      "|     Modules      | Parameters |\n",
      "+------------------+------------+\n",
      "| embedding.weight |  5099050   |\n",
      "|  convs.0.weight  |   15000    |\n",
      "|   convs.0.bias   |    100     |\n",
      "|  convs.1.weight  |   20000    |\n",
      "|   convs.1.bias   |    100     |\n",
      "|  convs.2.weight  |   25000    |\n",
      "|   convs.2.bias   |    100     |\n",
      "|    fc.weight     |    300     |\n",
      "|     fc.bias      |     1      |\n",
      "+------------------+------------+\n",
      "Total Trainable Params: 5159651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<prettytable.PrettyTable at 0x7f82abf785b0>, 5159651)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_model_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+\n",
      "|     Modules      | Parameters |\n",
      "+------------------+------------+\n",
      "| embedding.weight |  5099050   |\n",
      "|  convs.0.weight  |   15000    |\n",
      "|   convs.0.bias   |    100     |\n",
      "|  convs.1.weight  |   20000    |\n",
      "|   convs.1.bias   |    100     |\n",
      "|  convs.2.weight  |   25000    |\n",
      "|   convs.2.bias   |    100     |\n",
      "|    fc.weight     |    300     |\n",
      "|     fc.bias      |     1      |\n",
      "+------------------+------------+\n",
      "Total Trainable Params: 5159651\n"
     ]
    }
   ],
   "source": [
    "summary, params = count_model_parameters(model)\n",
    "\n",
    "tempdir = tempfile.mkdtemp()\n",
    "try:\n",
    "    summary_file = os.path.join(tempdir, \"model_summary.txt\")\n",
    "    with open(summary_file, \"w\") as f:\n",
    "        f.write(str(summary))\n",
    "\n",
    "    try_mlflow_log(mlflow.log_artifact, local_path=summary_file)\n",
    "finally:\n",
    "    shutil.rmtree(tempdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/pytorch/captum/blob/master/tutorials/models/imdb-model-cnn.pt\n",
    "# Download the model from this repo and save it in models directory\n",
    "\n",
    "model = torch.load('imdb-model-cnn.pt')\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_with_sigmoid(input):\n",
    "    return torch.sigmoid(model(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "TEXT = torchtext.data.Field(lower=True, tokenize='spacy')\n",
    "Label = torchtext.data.LabelField(dtype = torch.float)\n",
    "\n",
    "train, test = torchtext.datasets.IMDB.splits(text_field=TEXT,\n",
    "                                      label_field=Label,\n",
    "                                      train='train',\n",
    "                                      test='test',\n",
    "                                      path='data/aclImdb')\n",
    "\n",
    "test, _ = test.split(split_ratio = 0.04)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_mlflow_log(mlflow.log_param, \"Train Size\", len(train))\n",
    "try_mlflow_log(mlflow.log_param, \"Test Size\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:  101513\n"
     ]
    }
   ],
   "source": [
    "from torchtext import vocab\n",
    "\n",
    "# It will automatically download Glove embedding one time\n",
    "\n",
    "loaded_vectors = vocab.GloVe(name='6B', dim=50)\n",
    "\n",
    "TEXT.build_vocab(train, vectors=loaded_vectors, max_size=len(loaded_vectors.stoi))    \n",
    "TEXT.vocab.set_vectors(stoi=loaded_vectors.stoi, vectors=loaded_vectors.vectors, dim=loaded_vectors.dim)\n",
    "Label.build_vocab(train)\n",
    "\n",
    "print('Vocabulary Size: ', len(TEXT.vocab))\n",
    "\n",
    "mlflow.log_param(\"Vocabulary Size\", len(TEXT.vocab))\n",
    "\n",
    "PAD_IND = TEXT.vocab.stoi['pad']\n",
    "token_reference = TokenReferenceBase(reference_token_idx=PAD_IND)\n",
    "lig = LayerIntegratedGradients(model, model.embedding)\n",
    "\n",
    "vis_data_records_ig = []\n",
    "\n",
    "def interpret_sentence(model, sentence, min_len = 7, label = 0):\n",
    "    text = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    if len(text) < min_len:\n",
    "        text += ['pad'] * (min_len - len(text))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in text]\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    input_indices = torch.tensor(indexed, device=device)\n",
    "    input_indices = input_indices.unsqueeze(0)\n",
    "    \n",
    "    # input_indices dim: [sequence_length]\n",
    "    seq_length = min_len\n",
    "\n",
    "    # predict\n",
    "    pred = forward_with_sigmoid(input_indices).item()\n",
    "    pred_ind = round(pred)\n",
    "\n",
    "    # generate reference indices for each sample\n",
    "    reference_indices = token_reference.generate_reference(seq_length, device=device).unsqueeze(0)\n",
    "\n",
    "    # compute attributions and approximation delta using layer integrated gradients\n",
    "    attributions_ig, delta = lig.attribute(input_indices, reference_indices, \\\n",
    "                                           n_steps=500, return_convergence_delta=True)\n",
    "\n",
    "    print('pred: ', Label.vocab.itos[pred_ind], '(', '%.2f'%pred, ')', ', delta: ', abs(delta))\n",
    "\n",
    "    add_attributions_to_visualizer(attributions_ig, text, pred, pred_ind, label, delta, vis_data_records_ig)\n",
    "    \n",
    "def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records):\n",
    "    attributions = attributions.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    attributions = attributions.cpu().detach().numpy()\n",
    "\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
    "                            attributions,\n",
    "                            pred,\n",
    "                            Label.vocab.itos[pred_ind],\n",
    "                            Label.vocab.itos[label],\n",
    "                            Label.vocab.itos[1],\n",
    "                            attributions.sum(),       \n",
    "                            text,\n",
    "                            delta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  pos ( 0.99 ) , delta:  tensor([2.2198e-05], dtype=torch.float64)\n",
      "pred:  pos ( 1.00 ) , delta:  tensor([6.6302e-05], dtype=torch.float64)\n",
      "pred:  pos ( 1.00 ) , delta:  tensor([0.0003], dtype=torch.float64)\n",
      "pred:  pos ( 0.69 ) , delta:  tensor([0.0003], dtype=torch.float64)\n",
      "pred:  neg ( 0.22 ) , delta:  tensor([0.0011], dtype=torch.float64)\n",
      "pred:  pos ( 0.80 ) , delta:  tensor([0.0008], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "interpret_sentence(model, 'It was a fantastic performance !', label=1)\n",
    "interpret_sentence(model, 'Best film ever', label=1)\n",
    "interpret_sentence(model, 'Such a great show!', label=1)\n",
    "interpret_sentence(model, 'It was a horrible movie', label=0)\n",
    "interpret_sentence(model, 'I\\'ve never watched something as bad', label=0)\n",
    "interpret_sentence(model, 'It is a disgusting movie!', label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=[\"raw_input\", \"attr_class\", \"attr_score\", \"convergence_score\", \"pred_prob\", \"true_class\", \"word_attributions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(vis_data_records_ig)):\n",
    "    result.loc[i] = [vis_data_records_ig[i].raw_input, vis_data_records_ig[i].attr_class, vis_data_records_ig[i].attr_score, vis_data_records_ig[i].convergence_score, vis_data_records_ig[i].pred_prob, vis_data_records_ig[i].true_class, vis_data_records_ig[i].word_attributions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_input</th>\n",
       "      <th>attr_class</th>\n",
       "      <th>attr_score</th>\n",
       "      <th>convergence_score</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>true_class</th>\n",
       "      <th>word_attributions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[It, was, a, fantastic, performance, !, pad]</td>\n",
       "      <td>pos</td>\n",
       "      <td>-0.608882</td>\n",
       "      <td>[tensor(2.2198e-05, dtype=torch.float64)]</td>\n",
       "      <td>0.989221</td>\n",
       "      <td>pos</td>\n",
       "      <td>[-0.04036963633871359, -0.26865313379737765, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Best, film, ever, pad, pad, pad, pad]</td>\n",
       "      <td>pos</td>\n",
       "      <td>-1.095115</td>\n",
       "      <td>[tensor(6.6302e-05, dtype=torch.float64)]</td>\n",
       "      <td>0.998325</td>\n",
       "      <td>pos</td>\n",
       "      <td>[-0.22396408954050118, 0.09846007783400175, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Such, a, great, show, !, pad, pad]</td>\n",
       "      <td>pos</td>\n",
       "      <td>-0.588290</td>\n",
       "      <td>[tensor(-0.0003, dtype=torch.float64)]</td>\n",
       "      <td>0.996762</td>\n",
       "      <td>pos</td>\n",
       "      <td>[-0.1022866628788326, -0.6039511341403813, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[It, was, a, horrible, movie, pad, pad]</td>\n",
       "      <td>pos</td>\n",
       "      <td>-1.817970</td>\n",
       "      <td>[tensor(0.0003, dtype=torch.float64)]</td>\n",
       "      <td>0.688550</td>\n",
       "      <td>neg</td>\n",
       "      <td>[-0.035739643546623116, -0.09087759821024596, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[I, 've, never, watched, something, as, bad]</td>\n",
       "      <td>pos</td>\n",
       "      <td>-2.448575</td>\n",
       "      <td>[tensor(0.0011, dtype=torch.float64)]</td>\n",
       "      <td>0.216522</td>\n",
       "      <td>neg</td>\n",
       "      <td>[-0.09314164195969875, -0.438678035818444, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[It, is, a, disgusting, movie, !, pad]</td>\n",
       "      <td>pos</td>\n",
       "      <td>-2.015618</td>\n",
       "      <td>[tensor(0.0008, dtype=torch.float64)]</td>\n",
       "      <td>0.804903</td>\n",
       "      <td>neg</td>\n",
       "      <td>[-0.08236056046200133, -0.037739318701672284, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      raw_input attr_class  attr_score  \\\n",
       "0  [It, was, a, fantastic, performance, !, pad]        pos   -0.608882   \n",
       "1        [Best, film, ever, pad, pad, pad, pad]        pos   -1.095115   \n",
       "2           [Such, a, great, show, !, pad, pad]        pos   -0.588290   \n",
       "3       [It, was, a, horrible, movie, pad, pad]        pos   -1.817970   \n",
       "4  [I, 've, never, watched, something, as, bad]        pos   -2.448575   \n",
       "5        [It, is, a, disgusting, movie, !, pad]        pos   -2.015618   \n",
       "\n",
       "                           convergence_score  pred_prob true_class  \\\n",
       "0  [tensor(2.2198e-05, dtype=torch.float64)]   0.989221        pos   \n",
       "1  [tensor(6.6302e-05, dtype=torch.float64)]   0.998325        pos   \n",
       "2     [tensor(-0.0003, dtype=torch.float64)]   0.996762        pos   \n",
       "3      [tensor(0.0003, dtype=torch.float64)]   0.688550        neg   \n",
       "4      [tensor(0.0011, dtype=torch.float64)]   0.216522        neg   \n",
       "5      [tensor(0.0008, dtype=torch.float64)]   0.804903        neg   \n",
       "\n",
       "                                   word_attributions  \n",
       "0  [-0.04036963633871359, -0.26865313379737765, -...  \n",
       "1  [-0.22396408954050118, 0.09846007783400175, -0...  \n",
       "2  [-0.1022866628788326, -0.6039511341403813, 0.6...  \n",
       "3  [-0.035739643546623116, -0.09087759821024596, ...  \n",
       "4  [-0.09314164195969875, -0.438678035818444, -0....  \n",
       "5  [-0.08236056046200133, -0.037739318701672284, ...  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attr_file = \"word_attr.csv\"\n",
    "tempdir = tempfile.mkdtemp()\n",
    "try:\n",
    "    word_attr_file_path = os.path.join(tempdir, word_attr_file)\n",
    "    result.to_csv(word_attr_file_path)\n",
    "\n",
    "    try_mlflow_log(mlflow.log_artifact, local_path=word_attr_file_path)\n",
    "finally:\n",
    "    shutil.rmtree(tempdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualize attributions based on Integrated Gradients\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.61</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 70%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fantastic                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> performance                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-1.10</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Best                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(0, 75%, 62%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ever                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.59</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Such                    </font></mark><mark style=\"background-color: hsl(0, 75%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 69%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> great                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> show                    </font></mark><mark style=\"background-color: hsl(0, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.69)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-1.82</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> horrible                    </font></mark><mark style=\"background-color: hsl(0, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.22)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-2.45</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> I                    </font></mark><mark style=\"background-color: hsl(0, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 've                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> never                    </font></mark><mark style=\"background-color: hsl(0, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> watched                    </font></mark><mark style=\"background-color: hsl(0, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> something                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.80)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-2.02</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> disgusting                    </font></mark><mark style=\"background-color: hsl(0, 75%, 75%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pad                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Visualize attributions based on Integrated Gradients')\n",
    "visualization.visualize_text(vis_data_records_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(vis_data_records_ig)):\n",
    "    input_string = ' '.join(vis_data_records_ig[i].raw_input)\n",
    "    score = vis_data_records_ig[i].attr_score    \n",
    "    try_mlflow_log(mlflow.log_metric, \"Attribution Score\" + str(i), float(score), step=i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
